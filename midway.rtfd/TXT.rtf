{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red191\green191\blue191;}
{\info
{\title Formatting Instructions for NIPS -17-}
{\author NIPS publication chair}
{\*\company Microsoft Corporation}}\margl2160\margr2160\vieww19700\viewh14580\viewkind1
\deftab720
\pard\pardeftab720\ri0\sl226\slmult1\sb280\sa280\qc\partightenfactor0

\f0\b\fs34 \cf0 \kerning1\expnd5\expndtw28
\
Midway Report for 10601
\fs20 \kerning1\expnd1\expndtw5
\
\pard\tx2610\tx5670\pardeftab720\ri0\sl226\slmult1\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
\
                             Jinhong Chen\kerning1\expnd1\expndtw5
\super                                           \kerning1\expnd1\expndtw5
\nosupersub Da Wang\
\pard\tx2610\tx5670\pardeftab720\ri0\sl226\slmult1\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
                     {\field{\*\fldinst{HYPERLINK "mailto:jinhongc@andrew.cmu.edu"}}{\fldrslt jinhongc@andrew.cmu.edu}}                    {\field{\*\fldinst{HYPERLINK "mailto:dawang@andrew.cmu.edu"}}{\fldrslt dawang@andrew.cmu.edu}}\
\pard\pardeftab720\ri0\sl226\slmult1\sb540\sa140\qc\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd1\expndtw6
Abstract\
\pard\pardeftab720\li720\ri720\sl226\slmult1\sb120\sa100\qj\partightenfactor0

\b0\fs20 \cf0 \kerning1\expnd1\expndtw5
This is the midterm report for project of Introduction to Machine Learning(10-601, Fall 2015). In this project, we perform several machine learning method to classify images on the CIFAR-10[1] database. Conducted by an empirical study, the goal is to investigate the performance of different classifiers with different features and Principle Component Analysis(PCA). We also test deep learning algorithm with unsupervised feature extraction. Currently, by using neural network with hog feature, we can obtain a testing accuracy of 52%, which is 4% higher than the baseline implementation.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd4\expndtw24
1	INTRODUCTION\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0\fs20 \cf0 \kerning1\expnd1\expndtw5
Classifying images to different categories is the main focus for automatic recognition. In order to achieve higher precision, various methods of computer vision are proposed. Nowadays, deep learning is one of the most popular and effective machine learning techniques in this domain because of its ability of modeling image data with high-level abstractions[2]. The number of dimensions of deep learning algorithm can be extremely large which is barely possible for human to understand. However, traditional computer vision features such as GIST, Scale-invariant Feature Transform(SIFT), Speeded Up Robust Features(SURF), HOG are also significant for accurately image classification. Instead of using the raw pixel data, the features mentioned above can capture different structures such as edges, lines, orientations, etc[3].\
As the main focus of these project is to test different machine learning algorithms, the precision of classification will not be the only criteria of the project. Instead, we will use different features to evaluate the performance of Logistic Regression, Naive Bayes, Neural Network and Support Vector Machine. Besides, we also use Principle Component Analysis(PCA) to reduce the dimensions of features to improve accuracy. In order to find the best parameter for each machine learning algorithm, we tuned the parameters with many options and then compare their performance.\
Another work for this project is building a data preprocessing pipeline so as to eliminate outliers in the training data. The idea of this method is to use better training data to get better classifier. So we cover all three factors that may affect the precision of classification. Data preprocessing contribute to better training data. Different feature extraction and PCA method contribute to more effective descriptor. Testing different machine learning algorithm can find the best machine learning technique that meets our needs.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd4\expndtw24
2	BACKGROUND
\b0\fs20 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
This section introduce the dataset, feature and machine learning algorithm related to this project. \
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.1	Dataset\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
The CIFAR-10 is a labeled subset of 80 million tiny images which consists of 60000 32x32 color images in 10 classes, with 6000 per class. There are 50000 training images and 10000 test images. Below is a random sample from the CIFAR-10 with 10 random images from each class.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic 1.jpg \width6040 \height4760
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0
\cf0 \
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qc\partightenfactor0

\f0\fs20 \cf0 \kerning1\expnd1\expndtw5
Figure 1. a sample of images in CIFAR-10\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.2	HOG feature\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
In computer vision, it is critical to find proper visual features so that complex tasks can be performed. In this project, it is better to use the features of the image as they are more descriptive than the raw image pixel. Compared with SIFT which captures the properties at key points, HOG describes the shapes of a given region in a broader scope. Also, HOG is typically used in a sliding window fashion in object detection systems. The images in CIFAR-10 are quite small(32x32) so it may be better to use HOG in this project.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.3	SIFT feature\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
SIFT computes the gradient histogram only for patches (usually 16*16 divided into 16 cells) around specific interest points obtained by taking the DoG's (as an approximation to LoG's) in the scale space. It is a local descriptor which makes it perform bad when the input images are small.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.4	GIST feature\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
GIST is typically computed over the entire image (i.e. it is a global image descriptor) for the purposes of scene classification. The idea is similar to HOG which focus on the global feature rather than the key points. So it is also a good choice to use GIST features.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.5	Logistic Regression\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
Logistic regression is one of the most useful linear classifier in machine learning. Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution. The logistic function is shown below:\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic e1.jpg \width1960 \height860
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
We can use Maximum Conditional Likelihood Estimation(MCLE) to train the model.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.6	Neural Network\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
Unlike logistic regression, neural network with multiple hidden layers can be regarded as non-linear classifier. It has been proven to be powerful in many domains especially image classification. Typically, a neural network can be composed of a large number of interconnected computing elements in order to learn high level features from the input layer. An example of the structure of a neural network is shown below:\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic 2.png \width2960 \height3560
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
Figure 2. a sample of neural network with one hidden layer\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
However, neural network cannot provide a explicit learning process of its hidden layers. In order to find the best parameters, we usually increase the number of hidden layers which takes more time to train the neural network. After comparing the performance under different parameters, we can select the best neural network model.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.7	Support Vector Machine\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
SVM is a discriminative training process of linear classifier by maximizing the margin hyperplane of classification[4]:\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic e2.jpg \width2760 \height1000
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
As CIFAR-10 dataset contains 10 different classes, we need to use the multi-class SVM to classify the images. Using kernel functions, SVM can often find the proper linear spreadable hyperplane in higher dimension while the data is not linear separable originally. We have tested several kernel function and it turns out that the Radial Basis Function(RBF) kernel performs better in this project.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic e3.jpg \width3640 \height640
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
Here \uc0\u947  is the kernel parameter. The optimal value of \u947  should be selected by cross validation method.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
2.8	Principle Component Analysis(PCA)\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
PCA refers to a specific form of dimension reduction where the principle components are drawn on the sequentially orthogonal axes of the largest variance. It provides a way to reduce dimensionality without losing too much information[5]. With the help of PCA, we can build a model without redundant or irrelevant features.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd4\expndtw24
3	METHOD\
\pard\pardeftab720\ri0\partightenfactor0

\b0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.1	Feature Extraction\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
In the project so far, we tried two kind of feature extraction method before classification. One is the raw intensity of the image, the other is the Histogram of Oriented Gradient (HOG).\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.1.1	Raw Intensity\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
When using the raw intensity as the feature, we did not extract feature from the images. Each image (row) in the testing data X was treated as the feature of the image, and input directly to the classifiers. The raw intensity, as a kind of feature, represent the isolated color value of the pixel in the images.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.1.2	Histograms of Oriented Gradient ( HOG )\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
The HOG feature was extracted from the images using a open source library ( VLFeat ) by first transforming each image (row) to a matrix and calling the \'91vl_hog\'92 routine.\
The HOG feature extract the orientation feature from the image by counting the occurrences of gradient orientation in local patches of the images, and place them in discrete bin which forms the histogram of gradients. The magnitude of the gradient is used as the vote on the histogram. The HOG feature captures the information of edges ( oriented gradients ) in the images, since gradient near the edge will have large magnitude.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.2	Classifiers\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
Second level headings are lower case (except for first word and proper nouns), flush left, bold and in point size 10. One line space before the second level heading and \'bd line space after the second level heading.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.2.1	Na\'efve Bayes Classifier\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
To implement the Na\'efve Bayes Classifier, we optimized the classifier we implemented in Homework 1 by vectorizing calculation both in classification.\
In training stage, the classifier calculates mean and variance of each feature in each class. Each feature in each class is considered a Gaussian distribution independently. And later in classification stage, the classifiers calculate the probability of the input sample belonging to each class, and pick the class which maximize the probability to be the result.\
\
\pard\pardeftab720\ri0\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
3.2.2	Logistic Regression ( Softmax )\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
Since the Logistic Regression technique can only classify binary target. We extended our Logistic Regression to Softmax Regression, by using a 3rd party function optimizer ( minFunc ) to find the parameters which minimize the error. The Softmax regression is a generalized version of logistic regression in that it estimates the probability of a data belonging to a class in a way similar to logistic regression (using sigmoid). However, it supports multi class classification.\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b \cf0 \kerning1\expnd1\expndtw5
3.2.3	Neural Network
\b0 \kerning1\expnd1\expndtw5
\
We implemented our neural network using Feedforward and Back propagation algorithm with an adjustable size of hidden units with 3 layer (input + hidden + output). \
\
\pard\pardeftab720\ri0\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd4\expndtw24
4	RESULT\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0\fs20 \cf0 \kerning1\expnd1\expndtw5
These instructions apply to everyone, regardless of the formatter being used.\
\

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
Feature+Classifier\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 Accuracy()\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 Raw+NB\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 29.1%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 Raw+LR\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 26.2%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 HOG+NB\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 47.6%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\partightenfactor0
\cf0                           HOG+LR\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 45.5%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 HOG+NN(3L+25N)\cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 47.9%\cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell \row

\itap1\trowd \taflags1 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx4320
\clvertalc \clshdrawnil \clbrdrt\brdrs\brdrw20\brdrcf2 \clbrdrl\brdrs\brdrw20\brdrcf2 \clbrdrb\brdrs\brdrw20\brdrcf2 \clbrdrr\brdrs\brdrw20\brdrcf2 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell 
\pard\intbl\itap1\pardeftab720\ri0\sl226\slmult1\qc\partightenfactor0
\cf0 \cell \lastrow\row
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qc\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
Table 1. Comparison on different feature/classifier combination \
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0
\cf0 \kerning1\expnd1\expndtw5
\
\
\pard\pardeftab720\ri0\partightenfactor0

\b\fs24 \cf0 \kerning1\expnd4\expndtw24
5	CONCLUSION\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0\fs20 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb240\sa40\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
Acknowledgments\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0 \cf0 \kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb240\sa40\partightenfactor0

\b \cf0 \kerning1\expnd4\expndtw24
References\kerning1\expnd1\expndtw5
\
\pard\pardeftab720\ri0\sl226\slmult1\sb120\qj\partightenfactor0

\b0\fs18 \cf0 \kerning1\expnd1\expndtw5
[1] Alex, K. 2009. Learning multiple layers of features from tiny images\
[2] Honglak, L., Roger, G., Rajesh, R., and Andrew Y. Ng. 2009. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. ICML'09,609-616\
[3] Andreal, V., and Brian, F. 2010. Vlfeat: an open and portable library of computer vision algorithms. ACM, New York, NY 2010, 1469-1472\
[4] Leslie, C., Eleazar, E., and Stafford, W., 2001. The spectrum kernel: A string kernel for SVM protein classification. Pacific Symposium on Biocomputing. 566-575\
[5] Morre, B., 2009. Principal component analysis in  linear systems: Controllability, observability, and model reduction. Automatic Control, IEEE Transactions on Vol. 26. Issue. 1.}